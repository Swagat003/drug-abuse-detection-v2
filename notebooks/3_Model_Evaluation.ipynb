{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d044bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808d6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_npz(\"../Models/Features/X_test_tfidf.npz\")\n",
    "y_test = np.load(\"../Models/Features/y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d5150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model  = joblib.load(\"../Models/logistic_regression_model.pkl\")\n",
    "svm_model = joblib.load(\"../Models/linear_svm_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd1b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save(model, model_name):\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1_score\": f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    # -------------------------------\n",
    "    # Save metrics CSV\n",
    "    # -------------------------------\n",
    "    pd.DataFrame([metrics]).to_csv(\n",
    "        f\"../Models/Evaluation/metrics/{model_name}_metrics.csv\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # Save classification report\n",
    "    # -------------------------------\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    pd.DataFrame(report).transpose().to_csv(\n",
    "        f\"../Models/Evaluation/reports/{model_name}_classification_report.csv\"\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # Confusion Matrix Plot\n",
    "    # -------------------------------\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"No Drug\", \"Drug\"],\n",
    "        yticklabels=[\"No Drug\", \"Drug\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f\"../Models/Evaluation/confusion_matrices/{model_name}_confusion_matrix.png\",\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    # -------------------------------\n",
    "    # Metric Bar Plot (ZOOMED + VALUES)\n",
    "    # -------------------------------\n",
    "    metric_names = [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"]\n",
    "    values = [\n",
    "        metrics[\"accuracy\"],\n",
    "        metrics[\"precision\"],\n",
    "        metrics[\"recall\"],\n",
    "        metrics[\"f1_score\"]\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    bars = plt.bar(metric_names, values)\n",
    "\n",
    "    plt.ylim(0.95, 1.0)   # ðŸ”¥ zoomed axis\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(f\"Performance Metrics - {model_name}\")\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, values):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            val,\n",
    "            f\"{val:.3f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        f\"../Models/Evaluation/plots/{model_name}_metrics.png\",\n",
    "        dpi=300\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d769ba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'Logistic_Regression',\n",
       " 'accuracy': 0.9853420195439739,\n",
       " 'precision': 0.9911437246963563,\n",
       " 'recall': 0.9794948737184296,\n",
       " 'f1_score': 0.9852848698276946}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_lr = evaluate_and_save(lr_model, \"Logistic_Regression\")\n",
    "metrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b0ee7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'Linear_SVM',\n",
       " 'accuracy': 0.9859684289651717,\n",
       " 'precision': 0.9921499113699671,\n",
       " 'recall': 0.9797449362340586,\n",
       " 'f1_score': 0.9859084046300957}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_svm = evaluate_and_save(svm_model, \"Linear_SVM\")\n",
    "metrics_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75683e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
